# slurm.conf file generated by configurator.html.
# Put this file on all nodes of your cluster.
# See the slurm.conf man page for more information.
#

ControlMachine=admin
ControlAddr=10.0.10.1

# BackupController=
# BackupAddr=

AuthType=auth/munge
CacheGroups=0
CryptoType=crypto/munge

DisableRootJobs=YES 
#EnforcePartLimits=NO 
FirstJobId=3617

GresTypes=gpu

#GroupUpdateForce=0 
#GroupUpdateTime=600 
#CheckpointType=checkpoint/blcr 
#JobCheckpointDir=/share/home/slurm/checkpoint 

#JobCredentialPrivateKey=
#JobCredentialPublicCertificate=
#JobFileAppend=0 

JobRequeue=1 

#JobSubmitPlugins=1 

KillOnBadExit=1 

#Licenses=foo*4,bar
#MailProg=/share/home/slurm/sbin/mailer
#MaxJobCount=5000 
#MaxTasksPerNode=128 

MpiDefault=none

#MpiParams=ports=#-# 
#PluginDir= 
#PlugStackConfig= 
#PrivateData=jobs 

ProctrackType=proctrack/linuxproc
# ProctrackType=proctrack/sgi_job
# ProctrackType=proctrack/cgroup

#PropagatePrioProcess=0 
#PropagateResourceLimits= 

PropagateResourceLimitsExcept=ALL

#SallocDefaultCommand= 

SlurmctldPidFile=/var/run/slurmctld.pid
SlurmctldPort=6817
SlurmdPidFile=/var/run/slurmd.pid
SlurmdPort=6818
SlurmdSpoolDir=/tmp/slurmd
SlurmUser=slurm

StateSaveLocation=/share/home/slurm/checkpoint
SwitchType=switch/none

TaskPlugin=task/none
#TaskPluginParam=


TmpFs=/share/scr

# TrackWCKey=yes

#TreeWidth= 
#UnkillableStepProgram= 
# UsePAM=1

### TIMERS 
#BatchStartTimeout=10 
#CompleteWait=0 
#GetEnvTimeout=2 


InactiveLimit=0
KillWait=30

#MessageTimeout=10 
#ResvOverRun=0 

MinJobAge=300

#OverTimeLimit=0 

SlurmctldTimeout=120
SlurmdTimeout=300

#UnkillableStepTimeout=60 
#VSizeFactor=0 

Waittime=0

### SCHEDULING
FastSchedule=1

#MaxMemPerCPU=0 
#SchedulerRootFilter=1 
#SchedulerTimeSlice=30 

SchedulerType=sched/backfill
## SchedulerPort=7321

SelectType=select/cons_res
# SelectTypeParameters=CR_CPU_Memory
SelectTypeParameters=CR_CPU

# new config
# SelectTypeParameters=CR_Core,CR_CORE_DEFAULT_DIST_BLOCK

# JOB PRIORITY 
PriorityType=priority/multifactor
PriorityDecayHalfLife=2-0
#PriorityCalcPeriod= 
PriorityFavorSmall=no
PriorityMaxAge=3-0
#PriorityUsageResetPeriod= 
PriorityWeightAge=1000
PriorityWeightFairshare=10000
PriorityWeightJobSize=1000
PriorityWeightPartition=1000 
PriorityWeightQOS=1000

# 
# 
# LOGGING AND ACCOUNTING 
AccountingStorageEnforce=associations,limits
AccountingStorageHost=admin
#AccountingStorageLoc=
#AccountingStoragePass=
#AccountingStoragePort=6819
AccountingStoragePort=7031

AccountingStorageType=accounting_storage/slurmdbd
# AccountingStorageLoc=/var/log/slurm/accounting

#AccountingStorageUser=

ClusterName=cluster1

#DebugFlags= 
#JobCompHost=
#JobCompLoc=
#JobCompPass=
#JobCompPort=
# JobCompType=jobcomp/filetxt
#Â JobCompLoc=/var/log/slurm/jobcomp
#JobCompUser=

JobAcctGatherFrequency=30
JobAcctGatherType=jobacct_gather/linux
SlurmctldDebug=3

#SlurmctldLogFile=

SlurmdDebug=3

#SlurmdLogFile=
#SlurmSchedLogFile= 
#SlurmSchedLogLevel= 

### DRAIN
ReturnToService=1


### POWER SAVE SUPPORT FOR IDLE NODES
#SuspendProgram=/share/home/slurm/bin/Suspend
#ResumeProgram=/share/home/slurm/bin/Resume
#SuspendTimeout= 
#ResumeTimeout= 
#ResumeRate= 
#SuspendExcNodes= 
#SuspendExcParts=devel
#SuspendRate= 
#SuspendTime= 


### HEALTHCHECK
#HealthCheckInterval=86400
#HealthCheckProgram=/share/home/slurm/bin/HealthCheck


### PROLOG & EPILOG
# run as root on each node when job has completed
Epilog=/share/home/slurm/bin/Epilog
# EpilogMsgTime=2000

# run as SlurmUser on ControlMachine after the allocation is released:
EpilogSlurmctld=/share/home/slurm/bin/EpilogSlurmctld

# run by slurmd on each node prior to the first job step on the node:
Prolog=/share/home/slurm/bin/Prolog

# run by slurmctld as SlurmUser on ControlMachine before granting a job allocation:
PrologSlurmctld=/share/home/slurm/bin/PrologSlurmctld

# run by srun on the node running srun, prior to the launch of a job step:
SrunProlog=/share/home/slurm/bin/SrunProlog

# run by srun on the node running srun, after a job step finishes:
SrunEpilog=/share/home/slurm/bin/SrunEpilog

# run as user for each task prior to initiate the task:
TaskProlog=/share/home/slurm/bin/TaskProlog

# run as user for each task after the task finishes:
TaskEpilog=/share/home/slurm/bin/TaskEpilog


### CONTROL NODES
# admin node
# NodeName=admin RealMemory=8000 Sockets=1 CoresPerSocket=4 Feature=ib
# login node

NodeName=login RealMemory=8000 Sockets=1 CoresPerSocket=4 Feature=submit,login,all


### COMPUTE NODES
# flat topo
TopologyPlugin=topology/none
DefMemPerCPU=4000

# weight with thermal distribution
# U01
# GB Switch
# U02
NodeName=n001 Weight=118 RealMemory=34000 Sockets=2 CoresPerSocket=4 Gres=gpu:0 Feature=ib,compute,all
NodeName=n002 Weight=116 RealMemory=34000 Sockets=2 CoresPerSocket=4 Gres=gpu:0 Feature=ib,compute,all
# U03
NodeName=n003 Weight=122 RealMemory=34000 Sockets=2 CoresPerSocket=4 Gres=gpu:0 Feature=ib,compute,all
NodeName=n004 Weight=112 RealMemory=34000 Sockets=2 CoresPerSocket=4 Gres=gpu:0 Feature=ib,compute,all
# U04
NodeName=n005 Weight=108 RealMemory=34000 Sockets=2 CoresPerSocket=4 Gres=gpu:0 Feature=ib,compute,all
NodeName=n006 Weight=109 RealMemory=34000 Sockets=2 CoresPerSocket=4 Gres=gpu:0 Feature=ib,compute,all
# U05
NodeName=n007 Weight=109 RealMemory=34000 Sockets=2 CoresPerSocket=4 Gres=gpu:0 Feature=ib,compute,all
NodeName=n008 Weight=112 RealMemory=34000 Sockets=2 CoresPerSocket=4 Gres=gpu:0 Feature=ib,compute,all
# U06
NodeName=n009 Weight=112 RealMemory=34000 Sockets=2 CoresPerSocket=4 Gres=gpu:0 Feature=ib,compute,all
NodeName=n010 Weight=111 RealMemory=34000 Sockets=2 CoresPerSocket=4 Gres=gpu:0 Feature=ib,compute,all
# U07
NodeName=n011 Weight=106 RealMemory=34000 Sockets=2 CoresPerSocket=4 Gres=gpu:0 Feature=ib,compute,all
NodeName=n012 Weight=110 RealMemory=34000 Sockets=2 CoresPerSocket=4 Gres=gpu:0 Feature=ib,compute,all
# U08
NodeName=n013 Weight=109 RealMemory=34000 Sockets=2 CoresPerSocket=4 Gres=gpu:0 Feature=ib,compute,all
NodeName=n014 Weight=104 RealMemory=34000 Sockets=2 CoresPerSocket=4 Gres=gpu:0 Feature=ib,compute,all
# U09
NodeName=n015 Weight=107 RealMemory=34000 Sockets=2 CoresPerSocket=4 Gres=gpu:0 Feature=ib,compute,all
NodeName=n016 Weight=108 RealMemory=34000 Sockets=2 CoresPerSocket=4 Gres=gpu:0 Feature=ib,compute,all
# U10
NodeName=n017 Weight=112 RealMemory=34000 Sockets=2 CoresPerSocket=4 Gres=gpu:0 Feature=ib,compute,all
NodeName=n018 Weight=107 RealMemory=34000 Sockets=2 CoresPerSocket=4 Gres=gpu:0 Feature=ib,compute,all
# U11
NodeName=n019 Weight=104 RealMemory=34000 Sockets=2 CoresPerSocket=4 Gres=gpu:0 Feature=ib,compute,all
NodeName=n020 Weight=110 RealMemory=34000 Sockets=2 CoresPerSocket=4 Gres=gpu:0 Feature=ib,compute,all
# U12
NodeName=n021 Weight=109 RealMemory=34000 Sockets=2 CoresPerSocket=4 Gres=gpu:0 Feature=ib,compute,all
NodeName=n022 Weight=105 RealMemory=34000 Sockets=2 CoresPerSocket=4 Gres=gpu:0 Feature=ib,compute,all
# U13
NodeName=n023 Weight=104 RealMemory=34000 Sockets=2 CoresPerSocket=4 Gres=gpu:0 Feature=ib,compute,all
NodeName=n024 Weight=109 RealMemory=34000 Sockets=2 CoresPerSocket=4 Gres=gpu:0 Feature=ib,compute,all
# U14
NodeName=n025 Weight=109 RealMemory=34000 Sockets=2 CoresPerSocket=4 Gres=gpu:0 Feature=ib,compute,all
NodeName=n026 Weight=104 RealMemory=34000 Sockets=2 CoresPerSocket=4 Gres=gpu:0 Feature=ib,compute,all
# U15
NodeName=n027 Weight=109 RealMemory=34000 Sockets=2 CoresPerSocket=4 Gres=gpu:0 Feature=ib,compute,all
NodeName=n028 Weight=104 RealMemory=34000 Sockets=2 CoresPerSocket=4 Gres=gpu:0 Feature=ib,compute,all
# U16
NodeName=n029 Weight=109 RealMemory=34000 Sockets=2 CoresPerSocket=4 Gres=gpu:0 Feature=ib,compute,all
NodeName=n030 Weight=104 RealMemory=34000 Sockets=2 CoresPerSocket=4 Gres=gpu:0 Feature=ib,compute,all
# U17
NodeName=n031 Weight=109 RealMemory=34000 Sockets=2 CoresPerSocket=4 Gres=gpu:0 Feature=ib,compute,all
NodeName=n032 Weight=104 RealMemory=34000 Sockets=2 CoresPerSocket=4 Gres=gpu:0 Feature=ib,compute,all
# U18
# IB Switch
# U19
NodeName=n033 Weight=109 RealMemory=34000 Sockets=2 CoresPerSocket=4 Gres=gpu:0 Feature=ib,compute,all
NodeName=n034 Weight=104 RealMemory=34000 Sockets=2 CoresPerSocket=4 Gres=gpu:0 Feature=ib,compute,all
# U20
NodeName=n035 Weight=109 RealMemory=34000 Sockets=2 CoresPerSocket=4 Gres=gpu:0 Feature=ib,compute,all
NodeName=n036 Weight=104 RealMemory=34000 Sockets=2 CoresPerSocket=4 Gres=gpu:0 Feature=ib,compute,all
# U36
NodeName=gpu  Weight=104 RealMemory=34000 Sockets=2 CoresPerSocket=4 Gres=gpu:2 Feature=gpu,compute,all
# U37-38
# Admin
# U39-40
# Login
# U41-42
# UPS


### PARTITIONS

# devel partition
PartitionName=devel Nodes=gpu        State=UP AllowGroups=pdevel Shared=YES MaxTime=31-0

# common batch
PartitionName=batch Nodes=n[001-036] State=UP AllowGroups=pbatch Shared=NO  MaxTime=31-0 Default=YES
